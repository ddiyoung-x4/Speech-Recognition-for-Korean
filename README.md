# Speech-Recognition-for-Korean
주요 영역별 회의 음성 데이터를 활용한 한국어 음성인식 모델 개발 챌린지

**음성 데이터 학습 데이터셋 구축을 위한 전처리**
**1. wav 데이터 해석**  
1.1 주어진 wav 데이터의 재생시간(duration) 파악  
1.2 wav 데이터 내 subchunk section 데이터 분석  
(subchunk 데이터가 텍스트일 경우 텍스트로/오디오일 경우 duration)  
  
**2. 학습에 필요한 한국어 데이터 전처리**  
예) 데이터가 "b/ (70%)/(칠 십 퍼센트) 확률이라니 아/ (뭐+ 뭔)/(모+ 몬) 소리야 진짜 (100%)(백 프로)가 왜 안돼? n/" 일 경우  
        {  
            "original": "b/ (70%)/(칠 십 퍼센트) 확률이라니 아/ (뭐+ 뭔)/(모+ 몬) 소리야 진짜 (100%)(백 프로)가 왜 안돼? n/",  
            "new": "칠 십 퍼센트 확률이라니 아 모 몬 소리야 진짜 백 프로가 왜 안돼?"  
        }  
2.1 1차 필터링: ()/() 2지선다 에서 숫자 있는 부분 제거  
2.2 2차 필터링: 특수문자 b/, o/ 제거  
2.3 3차 필터링: 영어 단어 ex) NCS, npc, IV -> 엔씨에스, 엔피씨, 아이브이 변환  
  
**3. wav 유효 음성 구간(시작 점, 끝 점) 추출**  
데이터 Wave form에서 음성 구간이 시작하는 부분과 끝나는 부분을 알기 위해서는 일단 원본 데이터에서 Noise를 제거하는 작업이 필요  
3.1 음성 + Noise 데이터를 처리하기 위해 Noise Reduction, Filtering 수행  
<img width="80%" src="https://user-images.githubusercontent.com/69739208/184356999-db9cee03-ec05-4b1f-b16d-0e1c35751372.png"/>  
  
3.2 필터링된 음성 데이터에서 임의의 top_db, threshold를 정하여 유효 구간 추출  
